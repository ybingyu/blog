---
title: Web API(二)
date: 2021-12-01
---


<!-- ## 文档几何
- 文档坐标、视口坐标、容器坐标
- getBoundingClientRect() getClientRects 
- elementFromPoint()
- scrollTo scrollBy scrollIntoView
- 视口大小、内容大小、滚动位置 -->


## 组件
现在的前端开发基本离不开 React、Vue 这两个框架的支撑，还有angular，而这两个框架下面又衍生出了许多的自定义组件库：
- Element（Vue）
- Ant Design（React）

这些组件库的出现，让我们可以直接使用已经封装好的组件，而且在开源社区的帮助下，出现了很多的模板项目（ vue-element-admin、Ant Design Pro ），能让我们快速的开始一个项目。

以下表格内容提炼自尤雨溪本人对三大框架的对比看法：
![内容提炼自尤雨溪本人对三大框架的对比看法](https://gitee.com/bindyy/img/raw/master/webapi/640.png)

框架的优势包括但不限于：
- 数据绑定(单/双向)
- 组件化开发(各种钩子/生命周期/作用域隔离)
- 虚拟dom(diff算法)以及路由等。
- ......

但这些优势不是凭空而来，就像vue的双向绑定，从使用object.defineProperty转为使用proxy，这种类似的实现或者说转变，核心之处都需要js语法以及浏览器的原生支持。因为web应用最终都是要运行在宿主--浏览器上的，所以制定规范的各大浏览器厂商以及提供原生api支持的浏览器环境才是王道，而框架不是。我们之所以需要引入各类的框架、工具库去实现各种优秀的设计与思想，比如组件化，本质上是因为原生未直接提供对应的方式或是api，所以才需要框架去构建棋盘之上的又一层规则体系，来实现开发者的诉求。

而框架这种在浏览器原生规则之上又一层较高程度的封装，在带来便利高效的同时，不可避免的带来两个缺陷：

- 性能的下降，有时原生的直接操作指标要优于框架。
- 框架环境的隔离，例如vue的组件库没办法很好的衔接在react的项目中，这两者在组件的开发思路上，一个是自创的 JSX 语法，一个是特有的单文件模板的语法，两者的目标都是想提供一种组件的封装方法。

那么如果原生可以提供某些api，是不是就可以一定程度上替代框架的某些功能，在拥有便利高效的同时，跨平台、跨框架的使用，还能较大限度的保持原生的性能？

今天介绍的就是，通过 HTML、CSS、JS 的方式来实现自定义的组件，也是目前浏览器原生提供的方案：Web Components。

### 什么是Web Components
Web Components 它本身不是一个规范，它包含的几个规范，都已在 W3C 和 HTML 标准中进行了规范化，主要由三部分组成：

- ```Custom elements```（自定义元素）：一组 JavaScript API，用来创建自定义的 HTML标签，并允许标签创建或销毁时进行一些操作；
- ```HTML templates```（HTML模板）：通过 ```<template>```、```<slot>``` 直接在 HTML 文件中编写模板，然后通过 DOM API 获取。
- ```Shadow DOM```（影子DOM）：一组 JavaScript API，用于将创建的 DOM Tree 插入到现有的元素中，且 DOM Tree 不能被外部修改，不用担心元素被其他地方影响；
> HTML Imports 此规范已被废弃


兼容性可以查看 [can i use](https://caniuse.com/?search=web%20component)
现代浏览器。IE不支持


### 自定义元素
“自定义元素”是把一个HTML标签与一个JavaScript类关联起来，然后文档中出现的这个标签就会在DOM树种转换为响应的类的实例。
> 类比为Jq中自定义的插件


创建自定义元素需要使用```customElements.define()```方法。
- 第一个参数是组件的标签名（这个标签名必须至少包含一个连字符）
![不包含连字符会报错](https://gitee.com/bindyy/img/raw/master/webapi/3.png)
> 未来的HTML版本可以增加没有连字符的新标签，而这些标签不会跟任何人的Web组件冲突
- 第二个参数是一个```HTMLElement```的子类，也就是必须扩展```HTMLElement```。构造函数必须先调用super()然后才能使用this关键字
```javascript
class SearchBox extends HTMLElement {
    constructor() {
        super();// 调用超类的构造器，必须先调用

        let container = document.createElement('div')
        container.classList.add('search')

        let ipt = document.createElement('input')
        ipt.classList.add('ipt')
        container.appendChild(ipt)

        this.appendChild(container);
    }
}
window.customElements.define('search-box', SearchBox)
```
demo:[1.html](http://w.bindyy.cn/webcomponts/1.html)

```observedAttributes```，如果自定义元素定义了静态的这个属性，其值为一个属性名的数组。

如果任何这些命名属性在这个自定义元素的一个实例上被设置（或修改），浏览器就会调用```attributeChangedCallback```方法，传入属性名、旧值和新值。这个回调可以根据属性值的变化采取必要的步骤以更新组件
```javascript
static get observedAttributes() { return ['placeholder', 'width'] }
attributeChangedCallback(name, oldValue, newValue) {
    // ...
}
```
demo:[1.html](http://w.bindyy.cn/webcomponts/1.html)




### 使用Web组件
引入定义组件的Js文件
```javascript
    <script src="search1.js"></script>
```
在HTML页面上引用
```HTML
<search-box > </search-box>
```
注意，Web组件不能使用自关闭标签定义，比如不能写成```<search-box />```
也可以像常规的HTML标签一样具有属性
```HTML
<search-box width="200px" placeholder="2"> </search-box>
```
可以给Web组件设置子组件，这些子组件会出现在命名的“插槽”（```<slot>```）中
demo:[2.html](http://w.bindyy.cn/webcomponts/2.html)

当js还没有加载或者没有执行之前，即Web组件还没有定义就遇到其标签时，浏览器会向dom树中添加一个通用的HTMLElement。之后，当自定义元素有定义之后，这个通用元素会被“升级”，从而具备预期的外观和行为。

如果Web组件包含子元素，那么在组件有定义之前它们可能会被不适当的显示出来。可以使用下面的CSS将Web组件隐藏到它们有定义为止：
```CSS
search-box:not(:defined){
    visibility: hidden;
}
```
<!-- 看2.html 把js注释掉模拟 -->


### HTML模板
使用 JavaScript 写demo:[1.html](http://w.bindyy.cn/webcomponts/1.html)1的 DOM 结构很麻烦，```HTML```的```<template>```标签Web组件关系虽然没那么密切，但通过它可以对网页中频繁使用的组件进行优化。
<!-- 相比1.html -->

```<template>```标签及其子元素永远不会被浏览器渲染，只能在使用JavaScript的网页中使用。

在JavaScript中```<template>```标签对应的是一个```HTMLTemplateElement```对象。这个对象之定义了一个```content```属性，而这个属性的值是包含```<template>```所有子节点的```DocumentFragment```。可以克隆这个```DocumentFragment```，然后把克隆的副本插入文档中需要的地方。
demo:[3.html](http://w.bindyy.cn/webcomponts/3.html)
```HTML
<template id="search">
    <style>
        .ipt {
            border: 1px solid #ddd;
            padding: 5px
        }
    </style>
    <div class="search">
        <input type="text" class="ipt" placeholder="请输入搜索内容">
    </div>
</template>
```
```javascript
let templateElem = document.getElementById('search');
let content = templateElem.content.cloneNode(true);
```

### 影子DOM
我们不希望用户能够看到```<search-box>```的内部代码，Web 组件允许内部代码隐藏起来，这叫做 ```Shadow DOM```，即这部分 ```DOM``` 默认与外部 ```DOM``` 隔离，内部任何代码都无法影响外部。

自定义元素的```this.attachShadow()```方法开启```Shadow DOM```
```javascript
class SearchBox extends HTMLElement {
    constructor() {
        super();
        let shadow = this.attachShadow({ mode: 'closed' });

        SearchBox.template = document.createElement('template');
        SearchBox.template.innerHTML = `
        <style>
            .ipt{border:1px solid #ddd;padding:5px}
        </style>
        <div class="search">
            <input type="text" class="ipt" placeholder="请输入搜索内容">
        </div>
        `;
        let content = SearchBox.template.content.cloneNode(true);


        shadow.appendChild(content);
    }
}
```
demo:[4.html](http://w.bindyy.cn/webcomponts/4.html)
上面代码中，```this.attachShadow()```方法的参数```{ mode: 'closed' }```，表示 ```Shadow DOM``` 是封闭的，不允许外部访问。如果设置为```open```，表示可以从外部获取Shadow DOM内部的元素

- “影子DOM”中的“影子”是指作为子根节点后代的元素“藏在影子里”。也就是说，这个子树不属于常规DOM树，不会出现在它们宿主元素的```children```数组中，而且对```querySelector()```等常规DOM遍历方法也不可见。
- 如果指定模式是开放('open')的，影子数组会有一个```shadowRoot```属性，可以通过这个属性来访问影子根节点的元素
- 大多数情况下，阳光DOM的样式和影子DOM的样式是完全独立的。在影子根节点之下定义的样式是对该子树是私有的，不会影响外部的阳光DOM；外部阳光元素的DOM样式，也不会影响影子根节点。

### 生命周期
在```custom element```的构造函数中，可以指定多个不同的回调函数，它们将会在元素的不同生命时期被调用：

```connectedCallback```：当 ```custom element``` 首次被插入文档DOM时，被调用。
```disconnectedCallback```：当 ```custom element``` 从文档DOM中删除时，被调用。
```adoptedCallback```：当 custom element 被移动到新的文档时，被调用。
```attributeChangedCallback```: 当 custom element 增加、删除、修改自身属性时，被调用。

### 拓展
- [webcomponents.org](https://www.webcomponents.org/introduction)
- [https://mp.weixin.qq.com/s/WDbIN5Nsx09lTassnXqKWg](https://mp.weixin.qq.com/s/WDbIN5Nsx09lTassnXqKWg) ：自定义元素生命周期、影子DOM相关的其他api
- [https://www.webcomponents.org/](https://www.webcomponents.org/) 
- polyfills：https://www.webcomponents.org/polyfills/
- 开发库：[polymer](https://github.com/Polymer/polymer)、[LitElement](https://lit.dev/)、[stencil](https://github.com/github-rj/stencil)、[腾讯Omi](https://www.oschina.net/p/omi)、Slim.js
- Web Components UI组件库:[xy-ui](https://segmentfault.com/a/1190000019713345)、[Omiu](https://omi.cdn-go.cn/admin/latest/index.html#/docs/introduction)



## Web Audio API
```Web Audio API```提供了在Web上控制音频的一个非常有效通用的系统，允许开发者来自选音频源，对音频添加特效，使音频可视化，添加空间效果 （如平移），等等
<!-- 我们最初用web audio api库的时候，是为了解决H5中背景音与音效不能共存的问题，API提供了多声道 -->
### ```Audio``` 和 ```Web Audio``` 
![区别](https://gitee.com/bindyy/img/raw/master/webapi/webauido4.png)

Audio:
- 简单的音频播放器；
- 「单线程」的音频；
Web Audio:
- 音频合成；
- 可以做音频的各种处理；
- 游戏或可交互应用中的环绕音效；
- 可视化音频等等等等。

### 基础用法

```javascript
const context = new AudioContext();
fetch('sound.mp3')
  .then(response => response.arrayBuffer())
  .then(arrayBuffer => context.decodeAudioData(arrayBuffer))
  .then(audioBuffer => {
    const source = context.createBufferSource();
    source.buffer = audioBuffer;
    source.connect(context.destination);
    // 播放声音
    source.start();
  });
```
demo:[1.html](http://w.bindyy.cn/webaudio/1.html)


代码解释：
1. 通过```fetch```把音频数据请求下来；
2. 通过```context.decodeAudioData()```方法把音频数据(二进制)转换成我们所需要的```buffer```格式；
3. 通过```source.start()```方法把音频播放出来。
    1. source
    2. connect
    3. destination

首先我们通过 ```context.createBufferSource()``` 方法创建了一个「容器」 ```source``` 并装入接收进来的「水」 ```buffer```；其次通过「管道」 ```connect``` 把它和「出口」 ```destination``` 连接起来；最终「出口」 ```destination``` 「流」出来的就是我们所听到的音频了。


### AudioContext对象
```AudioContext```是一个专门用于音频处理的接口，并且原理是将```AudioContext```创建出来的各种**音频节点**（```AudioNode```）相互连接，音频数据流经这些节点并作出相应处理。



可以类比于```canvas```中的```context```，其中包含了一系列用来处理音频的 API，简而言之，就是可以用来控制音频的各种行为，比如播放、暂停、音量大小等。

```javascript
const audioContext = new AudioContext();
```

```javascript
//为了兼容，也可以这样写
window.AudioContext = window.AudioContext || window.webkitAudioContext || 
  window.mozAudioContext || window.msAudioContext;

//也可以使用错误处理
try {
    var context = new window.AudioContext();
} catch (e) {
    Console.log('!Your browser does not support AudioContext');
}
```
然后，获取音源文件，读取到的音频文件是二进制文件。将其在内存中解码，就可以播放声音了。

```context.decodeAudioData(binary, function(buffer) { ... });```

返回结果的```buffer```为```AudioBuffer```类型数据。
> 加载方式可以是 XMLHttpRequest 、 Ajax远程加载或者使用FileAPI读取本地文件



### AudioBuffer对象
![AudioBuffer对象](https://gitee.com/bindyy/img/raw/master/webapi/webauido1.png)
- ```length```:文件大小
- ```duration```:音频长度
- ```sampleRate```:浮点数，表示取样率，即一秒取样多少次。


### 创建音频处理节点
```AudioBufferSourceNode```对象  
![AudioBufferSourceNode对象](https://gitee.com/bindyy/img/raw/master/webapi/webauido2.png)   
- 播放```source.start()```
<!-- https://developer.mozilla.org/zh-CN/docs/Web/API/AudioBufferSourceNode/start -->
- 停止```source.stop()```

demo:[1.html](http://w.bindyy.cn/webaudio/1.html)   
但是暂停后再播放会得到一个报错。   
![只能播放一次](https://gitee.com/bindyy/img/raw/master/webapi/webauido3.png)  
一个 ```AudioBufferSourceNode``` 只能被播放一次，也就是说，每次调用 ```start()```  之后，如果还想再播放一遍同样的声音，那么就需要再创建一个 ```AudioBufferSourceNode```。创建该节点的代价并不大，并且想要多次播放声音的话，实际上 ```AudioBuffer``` 也可以被重用。事实上，你可以用一种“阅后即焚”的方式来使用这些节点：创建节点，调用 ```start()``` 开始播放声音，然后，你甚至不需要再保留这个节点的引用了。声音播放完成之后，垃圾收集器会找个恰当的时机回收资源。

多次调用 ```AudioBufferSourceNode.stop()``` 是允许的。如果这时候 ```AudioBufferSourceNode``` 还没有到达缓冲区末尾的话，最近一次的调用将替换上一次的调用。


### 音频节点(AudioNode)
到这里，大家应该大致知道了如何通过 ```AudioContext``` 去控制音频的播放。但是会发现写了这么一大堆做的事情和前面提到的```<audio>```所做的事情没什么区别，那么 ```AudioContext``` 具体是如何去处理我们前面所提到的那些 **「高级」** 的功能呢？就是我们接下来正要了解的 **音频节点**。

可以把它理解为是通过「管道」 ```connect``` 连接在「容器」 ```source``` 和「出口」 ```destination``` 之间一系列的音频「处理器」。 ```AudioContext``` 提供了许多「处理器」用来处理音频，比如音量「处理器」 ```GainNode```、延时「处理器」 ```DelayNode``` 或声道合并「处理器」 ```ChannelMergerNode``` 等等。

![AudioNode](https://gitee.com/bindyy/img/raw/master/webapi/webauido5.jpg)

前面所提到的「管道」 ```connect``` 也是由音频节点 ```AudioNode``` 提供的，所以，「容器」 ```source``` 也是一种音频节点。
```javascript
const source = audioContext.createBufferSource();

console.log(source instanceof AudioNode); // true
```

```AudioContext.destination```返回```AudioDestinationNode```对象，也是继承音频节点 ```AudioNode``` 的，表示当前 ```AudioContext``` 中所有节点的最终节点，一般表示音频渲染设备。

AudioNode 还提供了一系列的方法和属性：

- ```.context (read only)```: ```audioContext``` 的引用
- ```.channelCount```: 声道数
- ```.connect()```: 连接另外一个音频节点
- ```.start()```: 开始播放
- ```.stop()```: 停止播放


### 音量处理器(gainNode)

-----------

说明：

WebAudio API主要是为音频文件添加音效而设计的，但是它也可以用来播放音频文件，这类似于HTML5 audio元素的功能，只是audio元素可以有控制界面，用户可以点击界面上的播放/停止按钮来控制文件的播放，也可以拖动界面上的进度条来控制播放进度。而采用WebAudio API实现的音频播放则没有控制界面，但对于移动平台Android，IOS确实非常有用的，例如在Android平台上Chrome浏览器设置了gesture-requirement-for-media-playback属性，意思是说不能通过调用audio元素的play函数实现音频文件的播放，除了调用play函数之外，还必须要求用户在屏幕上有一个手势操作，该行为和苹果的IOS上的行为一致。

使用WebAudio播放音频文件的效率问题

前面介绍了如何使用WebAudio来播放音频文件，但是需要注意的是不要轻易采用WebAudio的该功能，因为当音频文件较大时，可能会影响程序的执行效率。首先，如果我们在程序中采用XMLHttpRequest去下载文件时，这是一个比较耗时的操作，具体的时间取决于当前的网络环境和文件的大小，尽管程序中采用异步的下载方式，但是同样会让音频的播放延迟。其次，程序需要调用WebAudio的decodeAudioData函数去解码整个音频文件，这里需要注意的是它需要一次性解码整个文件后，才会触发成功的回调函数，程序才能开始播放音频文件，这又一次的增加了音频文件播放的延迟，另外，由于整个文件的一次性解码，整个解码前和解码后的文件都同时存放在内存中，这也引起了内存的巨大开销（相比采用audio元素播放时，因为audio元素是一边解码一边播放）。此时可能有朋友会质疑decodeAudioData API的实现有问题，其实该函数是为解码比较短小的声音文件而设计的，另外由于WebAudio对音频的延时性特别关注，所以为了较少声音的延时，在音效处理前要求把需要处理的音频文件装载进内存。

所以如果需要使用WebAudio播放文件，又比较关注效率问题时，建议把音频文件的大小缩小一些，或者分解成若干小的文件再分别加载解码播放。

### context.createBuffer()
```context.createBuffer()```方法生成一个内存的操作视图，用于存放数据。
```javascript
const buffer = audioContext.createBuffer(channels, signalLength, sampleRate);
```
```createBuffer```方法接受三个参数。

- ```channels```：整数，表示声道。创建单声道的声音，该值为 1。
- ```signalLength```：整数，表示声音数组的长度。
- ```sampleRate```：浮点数，表示取样率，即一秒取样多少次。

```signalLength```和```sampleRate```这两个参数决定了声音的长度。比如，如果取样率是1/3000（每秒取样3000次），声音数组长度是6000，那么播放的声音是2秒长度。

接着，使用```buffer.getChannelData```方法取出一个声道。
```javascript
const data = buffer.getChannelData(0)
```
上面代码中，```buffer.getChannelData```的参数0表示取出第一个声道。 
下一步，将声音数组放入这个声道。
```javascript
const data = buffer.getChannelData(0)
// singal 是一个声音数组
// singalLengal 是该数组的长度
for (let i = 0; i < signalLength; i += 1) {
  data[i] = signal[i]
}
```
最后，使用```context.createBufferSource```方法生成一个声音节点。
```javascript
// 生成一个声音节点
const node = audioContext.createBufferSource();
// 将声音数组的内存对象，放入这个节点
node.buffer = buffer;
// 将声音上下文与节点连接
node.connect(audioContext.destination);
// 开始播放声音
node.start(audioContext.currentTime);
```
默认情况下，播放一次后就将停止播放。如果需要循环播放，可以将节点对象的looping属性设为true。

```javascript
node.looping = true;
```




创建声音-加载播放-暂停
录音
音频可视化
改变音量大小-渐变音量淡入淡出
库
- 处理器 https://mp.weixin.qq.com/s/2Xul8NTkxdzV2zru_TQQuA
- 过滤器 https://www.bookstack.cn/read/webapi-tutorial/docs-webaudio.md
- 系列https://www.cnblogs.com/tianma3798/p/6033613.html
- 音量淡入淡出 https://www.cnblogs.com/yangzhou33/p/9495915.html
- 语音对讲 https://mp.weixin.qq.com/s/0lulI8pVoXaORkU1_NvkMA
# BOM
## 位置导航历史
- assign\replace reload
- back forward go
- hash\hashchange （在uc浏览器及uc团队出品的夸克浏览器下 响应速度很慢）
- pushState() replaceState()  popstate事件===找点资料看看，书上有个猜数字的例子

## 网络
- fetch
- SSE
- WebSocket
可以是一个大章节-结合demo重点单开一课上一下？

## 存储
- storage:getItem setItem deleteItem clear、事件storage、跨站限制
- cookie
- IndexedDB

## Workers 线程






# 网络状态
# 电池状态
# 设备震动
# 页面状态
页面可见性
屏幕方向
page lifecycle(网页生命周期) https://juejin.cn/post/6844903741024370701#heading-0
# execCommand 执行命令
https://juejin.cn/post/6844903741024370701#heading-0



# IntersectionObserver 
https://juejin.cn/post/6844903874302574599#heading-0

# 全屏

# Wasm
https://mp.weixin.qq.com/s/to5HvlBp--vEhapjzM39aA